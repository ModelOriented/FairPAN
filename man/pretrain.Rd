% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pretrain.R
\name{pretrain}
\alias{pretrain}
\title{Pretrains both classifier and adversarial}
\usage{
pretrain(
  clf_model = NULL,
  adv_model = NULL,
  clf_optimizer = NULL,
  trained = FALSE,
  train_x = NULL,
  train_y = NULL,
  sensitive_train,
  sensitive_test,
  batch_size = 50,
  partition = 0.7,
  neurons_clf = c(32, 32, 32),
  neurons_adv = c(32, 32, 32),
  dimension_clf = 2,
  dimension_adv = 1,
  learning_rate_clf = 0.001,
  learning_rate_adv = 0.001,
  n_ep_preclf = 5,
  n_ep_preadv = 10,
  dsl,
  dev,
  verbose = TRUE,
  monitor = TRUE,
  seed = 7
)
}
\arguments{
\item{clf_model}{optional value, net, nn_module, provide the pretrain with your own
classification neural network. Default: NULL}

\item{adv_model}{optional value, net, nn_module, provide the pretrain with your own
adversarial neural network. Default: NULL}

\item{clf_optimizer}{optional value, provide the optimizer of classifier if
you decided to provide your own pre trained classifier. Default: NULL}

\item{trained}{0 if the classificator is untrained, 1 if the classificator
is already pretrained. Default: 0}

\item{train_x}{numeric, scaled matrix of predictors used for training}

\item{train_y}{numeric, scaled vector of target used for training}

\item{sensitive_train}{integer, vector of sensitive values used for training}

\item{sensitive_test}{integer, vector of sensitive values used for testing}

\item{batch_size}{integer indicating a batch size used in dataloader.
Default: 50}

\item{partition}{float from [0,1] range setting the size of train vector
(test size equals 1-partition). Default = 0.7.}

\item{neurons_clf}{integer vector describing a neural architecture of
classifier network. Default: c(32,32,32). This notation means that the
network has 3 layers with 32 neurons each.}

\item{neurons_adv}{integer vector describing a neural architecture of
adversarial network. Default: c(32,32,32). This notation means that the
network has 3 layers with 32 neurons each.}

\item{dimension_clf}{integer from [0,2] setting nnf_softmax dimension for
classifier. Default: 2 (suggested to use 2 for classifier and 1 for
adversarial)}

\item{dimension_adv}{integer from [0,2] setting nnf_softmax dimension for
adversarial. Default: 1 (suggested to use 2 for classifier and 1 for
adversarial)}

\item{learning_rate_clf}{float from [0,1] setting learning rate for
classifier. Default: 0.001}

\item{learning_rate_adv}{float from [0,1] setting learning rate for
classifier. Default: 0.001}

\item{n_ep_preclf}{integer setting number of epochs for preclassifiers
training. Default: 5}

\item{n_ep_preadv}{integer setting number of epochs for preadversarials
training. Default : 10}

\item{dsl}{dataset_loader object from pretrain}

\item{dev}{device used to calculations (cpu or gpu)}

\item{verbose}{logical indicating if we want to print monitored outputs or
not}

\item{monitor}{logical indicating if we want to monitor the learning process
or not (monitoring tends to slow down the training process, but provides
some useful info to adjust parameters and training process)}

\item{seed}{integer, seed for initial weights, set NULL for none. Default: 7.}
}
\value{
list of two objects : clf_model and adv_model which are pretrained
neural networks (net, nn_module).
}
\description{
Creates and pretrains both classifier and adversarial. The user is
also able to provide its own architecture of both models through clf_model
and adv_model parameters. Moreover the classifier can be also trained, but then
one has to change trained to TRUE and provide the optimizer from this training.
It is also possible to create both models from our interface witch is described
in create_model documentation.
}
\examples{
\dontrun{
adult <- fairmodels::adult

processed <-
  preprocess(
    adult,
    "salary",
    "sex",
    "Male",
    "Female",
    c("race"),
    sample = 0.05,
    train_size = 0.65,
    test_size = 0.35,
    validation_size = 0,
    seed = 7
  )

dev <- "cpu"

dsl <- dataset_loader(processed$train_x, processed$train_y, processed$test_x,
                      processed$test_y, batch_size = 5, dev = dev)

# Both models created with our package
models <- pretrain(
  train_x = processed$train_x,
  train_y = processed$train_y,
  sensitive_train = processed$sensitive_train,
  sensitive_test = processed$sensitive_test,
  batch_size = 5,
  partition = 0.65,
  neurons_clf = c(32, 32, 32),
  neurons_adv = c(32, 32, 32),
  dimension_clf = 2,
  dimension_adv = 1,
  learning_rate_clf = 0.001,
  learning_rate_adv = 0.001,
  n_ep_preclf = 1,
  n_ep_preadv = 1,
  dsl = dsl,
  dev = dev,
  verbose = FALSE,
  monitor = FALSE
)

# presaved models and states of the optimizers
clf                 <- torch_load(system.file("extdata","clf2",package="fairpan"))
clf_optimizer_state <- torch_load(system.file("extdata","clf_optimizer2",package="fairpan"))
clf_optimizer       <- optim_adam(clf$parameters, lr = 0.001)
acc2                <- eval_accuracy(clf, dsl$test_ds, dev)
clf_optimizer$load_state_dict(clf_optimizer_state)

# Clf provided and pretrained
models2 <- pretrain(
  clf_model = clf,
  clf_optimizer = clf_optimizer,
  trained = TRUE,
  train_x = processed$train_x,
  train_y = processed$train_y,
  sensitive_train = processed$sensitive_train,
  sensitive_test = processed$sensitive_test,
  batch_size = 5,
  partition = 0.65,
  neurons_clf = c(32, 32, 32),
  neurons_adv = c(32, 32, 32),
  dimension_clf = 2,
  dimension_adv = 1,
  learning_rate_clf = 0.001,
  learning_rate_adv = 0.001,
  n_ep_preclf = 1,
  n_ep_preadv = 1,
  dsl = dsl,
  dev = dev,
  verbose = FALSE,
  monitor = FALSE
)

clf2 <- create_model(processed$train_x, processed$train_y, c(4, 4), 2)

# Clf provided, but not pretrained
models3 <- pretrain(
  clf_model = clf2,
  trained = FALSE,
  train_x = processed$train_x,
  train_y = processed$train_y,
  sensitive_train = processed$sensitive_train,
  sensitive_test = processed$sensitive_test,
 batch_size = 5,
  partition = 0.65,
  neurons_clf = c(32, 32, 32),
  neurons_adv = c(32, 32, 32),
  dimension_clf = 2,
  dimension_adv = 1,
  learning_rate_clf = 0.001,
  learning_rate_adv = 0.001,
  n_ep_preclf = 1,
  n_ep_preadv = 1,
  dsl = dsl,
  dev = dev,
  verbose = FALSE,
  monitor = FALSE
)
}

}
