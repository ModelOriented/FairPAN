<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Comfortable Tool for Making Fair Classifier with the Neural Networks • fairpan</title>
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="bootstrap-toc.css">
<script src="bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- dalexverse --><link href="dalexverse.css" rel="stylesheet">
<link href="dalexverse-2.css" rel="stylesheet">
<!-- pkgdown --><link href="pkgdown.css" rel="stylesheet">
<script src="pkgdown.js"></script><meta property="og:title" content="Comfortable Tool for Making Fair Classifier with the Neural Networks">
<meta property="og:description" content="The tool not only for creating fair predictive adversarial networks, but also for monitoring the training process and visualizing its outcomes. This package is really flexible, because the user can not only provide its own neural network models, but also create them with our functions.">
<meta name="robots" content="noindex">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- google analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-5650686-14"></script><script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());

 gtag('config', 'UA-5650686-14');
</script>
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-home">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>

      <div class="navbar-brand-container">
        <a class="navbar-brand" href="index.html">fairpan</a>
        <div class="info">
          <span class="partof">part of the <a href="https://github.com/ModelOriented/DrWhy">DrWhy.AI</a>
           developed by the <a href="https://mi2.mini.pw.edu.pl/">MI^2 DataLab</a> </span>
          <span class="version version-default">0.1.0</span>
        </div>
      </div>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav navbar-right">
<li>
  <a href="index.html">
    <span class="fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="articles/Tutorial.html">FairPAN Tutorial</a>
    </li>
  </ul>
</li>
        <li>
  <a href="https://github.com/ModelOriented/FairPAN">
    <span class="fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><div class="row">
  <div class="contents col-md-9">
<div id="fairpan---fair-predictive-adversarial-network" class="section level1">
<div class="page-header"><h1 class="hasAnchor">
<a href="#fairpan---fair-predictive-adversarial-network" class="anchor"></a>FairPAN - Fair Predictive Adversarial Network</h1></div>
<!-- badges: start -->

<div id="overview" class="section level2">
<h2 class="hasAnchor">
<a href="#overview" class="anchor"></a>Overview</h2>
<p>Have you just created a model which is biased against some subgroup? Or have you just tried to fight the bias, but models performance dropped significantly? Use <code>FairPAN</code> to create neural network model that provides fair predictions and achieves outstanding performance! With <code><a href="reference/pretrain.html">pretrain()</a></code> you can create or provide your own neural networks and then use them in <code><a href="reference/fair_train.html">fair_train()</a></code> to achieve fair outcomes. R package FairPAN additionally allows you to use lots of <a href="https://github.com/ModelOriented/DALEX">DALEX</a> and <a href="https://github.com/ModelOriented/fairmodels">fairmodels</a> functions such as <code><a href="https://dalex.drwhy.ai/reference/model_performance.html">DALEX::model_performance()</a></code> or <code><a href="https://rdrr.io/pkg/fairmodels/man/fairness_check.html">fairmodels::fairness_check()</a></code>.</p>
<p><em>If you have problems with the training process remember to use monitor parameter and plot_monitor function for parameter adjustments.</em></p>
<p>Check <a href="https://modeloriented.github.io/FairPAN/">FairPAN Website</a>!</p>
</div>
<div id="theoretical-introduction" class="section level2">
<h2 class="hasAnchor">
<a href="#theoretical-introduction" class="anchor"></a>Theoretical introduction</h2>
<div id="introduction-to-fairness" class="section level3">
<h3 class="hasAnchor">
<a href="#introduction-to-fairness" class="anchor"></a>Introduction to Fairness</h3>
<p>Consider the idea of the algorithm that has to predict whether giving credit to a person is risky or not. It is learning on real data of giving credits which were biased against females (historical fact). In that case, the model learns this bias, which is not only included in the simple sex variable but also is hidden inside other variables. Fairness enables us to detect such bias and handles a few methods to fight it. To learn more, I recommend the article <a href="%22https://arxiv.org/pdf/2104.00507.pdf%22">‘Fairmodels: A Flexible Tool For Bias Detection, Visualization, And Mitigation’ by Jakub Wisniewski and Przemysław Biecek</a>.</p>
</div>
<div id="introduction-to-gans" class="section level3">
<h3 class="hasAnchor">
<a href="#introduction-to-gans" class="anchor"></a>Introduction to GANs</h3>
<p>Generative Adversarial Networks are two neural networks that learn together. The Generator has to generate new samples that are indistinguishable from original data and the adversarial has to distinguish if the observation is original or generated. The generator is punished whenever the adversarial makes the correct prediction. After such process generator eventually learns how to make indistinguishable predictions and adversaries’ accuracy drops down to 50% when a model cannot distinguish the two classes. The idea of GANs was proposed in <a href="https://arxiv.org/pdf/1406.2661.pdf">Generative Adversarial Nets, Ian Goodfellow</a>.</p>
</div>
<div id="fairpan" class="section level3">
<h3 class="hasAnchor">
<a href="#fairpan" class="anchor"></a>FairPAN</h3>
<p>FairPANs are the solution to bring fairness into neural networks. We mimic the GANs by subsetting generator with classifier (predictor) and adversarial has to predict the sensitive value (such as sex, race, etc) from the output of the predictor. This process eventually leads the classifier to make predictions with indistinguishable sensitive values. The idea comes from blogs: <a href="https://godatadriven.com/blog/towards-fairness-in-ml-with-adversarial-networks/">Towards fairness in ML with adversarial networks, Stijn Tonk</a> and <a href="https://godatadriven.com/blog/fairness-in-machine-learning-with-pytorch/">Fairness in Machine Learning with PyTorch, Henk Griffoen</a> however, our implementation in R offers slightly different solutions. And the exact idea behind using GANs for Fairness is described in <a href="https://stanford.edu/~cpiech/bio/papers/fairnessAdversary.pdf">Achieving Fairness through Adversarial Learning: an Application to Recidivism Prediction, Christina Wadsworth, Francesca Vera, Chris Piech</a>.</p>
<center>
<img src="./man/images/architecture_PAN.png" alt="drawing">
</center>
<p>The diagram above represents the architecture of our model and is strongly inspired by aforementioned blogs.</p>
</div>
<div id="custom-loss-function" class="section level3">
<h3 class="hasAnchor">
<a href="#custom-loss-function" class="anchor"></a>Custom Loss Function</h3>
<p>The crucial part of this model is the metric we use to engage the two models into a zero-sum game. This is captured by the following objective function:</p>
<center>
<img src="./man/images/equation.png" alt="drawing" height="40">
</center>
<p>So, it learns to minimize its prediction losses while maximizing that of the adversarial (due to lambda being positive and minimizing a negated loss is the same as maximizing it). The objective during the game is simpler for the adversarial: predict sex based on the income level predictions of the classifier. This is captured in the following objective function:</p>
<center>
<img src="./man/images/equation2.png" alt="drawing" height="40">
</center>
<p>The adversarial does not care about the prediction accuracy of the classifier. It is only concerned with minimizing its prediction losses. Firstly we pretrain classifier and adversarial. Later we begin the proper PAN training with both networks: we train the adversarial, provide its loss to the classifier, and after that, we train the classifier. This method shall lead us to fair predictions of the FairPAN model.</p>
</div>
</div>
<div id="why" class="section level2">
<h2 class="hasAnchor">
<a href="#why" class="anchor"></a>Why?</h2>
<p>Regular mitigation techniques tend to worsen performance of the classifier a lot by decreasing accuracy for example, whereas FairPAN has no such drawback and worsening of the performance is really small. Moreover, our package is very flexible because it enables to provide your own neural networks, but also to create one with our functions. The outcomes are also created with the usage of <code>DALEX</code> and <code>fairmodels</code>, so one can use their methods and visualizations. Additionally the workflow of the package is really simple and clean, because of multiple features available for user, such as <code>preprocess</code> function.</p>
</div>
<div id="installation" class="section level2">
<h2 class="hasAnchor">
<a href="#installation" class="anchor"></a>Installation</h2>
<p>Install the developer version from GitHub:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">devtools</span><span class="fu">::</span><span class="fu">install_github</span><span class="op">(</span><span class="st">"ModelOriented/FairPAN"</span>,build_vignettes <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
</div>
<div id="example" class="section level2">
<h2 class="hasAnchor">
<a href="#example" class="anchor"></a>Example</h2>
<p>Achieve fairness and save performance!</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va">fairpan</span><span class="op">)</span>

<span class="va">adult</span> <span class="op">&lt;-</span> <span class="fu">fairmodels</span><span class="fu">::</span><span class="va"><a href="https://rdrr.io/pkg/fairmodels/man/adult.html">adult</a></span>

<span class="co"># ------------------- step 1 - prepare data  ------------------------</span>

<span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/preprocess.html">preprocess</a></span><span class="op">(</span> data <span class="op">=</span> <span class="va">adult</span>,
                    target_name <span class="op">=</span> <span class="st">"salary"</span>,
                    sensitive_name <span class="op">=</span> <span class="st">"sex"</span>,
                    privileged <span class="op">=</span> <span class="st">"Male"</span>,
                    discriminated <span class="op">=</span> <span class="st">"Female"</span>,
                    drop_also <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"race"</span><span class="op">)</span>,
                    sample <span class="op">=</span> <span class="fl">0.02</span>,
                    train_size <span class="op">=</span> <span class="fl">0.6</span>,
                    test_size <span class="op">=</span> <span class="fl">0.4</span>,
                    validation_size <span class="op">=</span> <span class="fl">0</span>,
                    seed <span class="op">=</span> <span class="fl">7</span>
<span class="op">)</span>

<span class="va">dev</span> <span class="op">&lt;-</span> <span class="st">"cpu"</span>

<span class="va">dsl</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/dataset_loader.html">dataset_loader</a></span><span class="op">(</span>train_x <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">train_x</span>,
                      train_y <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">train_y</span>,
                      test_x <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">test_x</span>,
                      test_y <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">test_y</span>,
                      batch_size <span class="op">=</span> <span class="fl">5</span>,
                      dev <span class="op">=</span> <span class="va">dev</span>
<span class="op">)</span>

<span class="co"># ------------ step 2 - create and pretrain models  -----------------</span>

<span class="va">models</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/pretrain.html">pretrain</a></span><span class="op">(</span>clf_model <span class="op">=</span> <span class="cn">NULL</span>,
                   adv_model <span class="op">=</span> <span class="cn">NULL</span>,
                   clf_optimizer <span class="op">=</span> <span class="cn">NULL</span>,
                   trained <span class="op">=</span> <span class="cn">FALSE</span>,
                   train_x <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">train_x</span>,
                   train_y <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">train_y</span>,
                   sensitive_train <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">sensitive_train</span>,
                   sensitive_test <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">sensitive_test</span>,
                   batch_size <span class="op">=</span> <span class="fl">5</span>,
                   partition <span class="op">=</span> <span class="fl">0.6</span>,
                   neurons_clf <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">32</span>, <span class="fl">32</span><span class="op">)</span>,
                   neurons_adv <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">32</span>, <span class="fl">32</span><span class="op">)</span>,
                   dimension_clf <span class="op">=</span> <span class="fl">2</span>,
                   dimension_adv <span class="op">=</span> <span class="fl">1</span>,
                   learning_rate_clf <span class="op">=</span> <span class="fl">0.001</span>,
                   learning_rate_adv <span class="op">=</span> <span class="fl">0.001</span>,
                   n_ep_preclf <span class="op">=</span> <span class="fl">10</span>,
                   n_ep_preadv <span class="op">=</span> <span class="fl">10</span>,
                   dsl <span class="op">=</span> <span class="va">dsl</span>,
                   dev <span class="op">=</span> <span class="va">dev</span>,
                   verbose <span class="op">=</span> <span class="cn">TRUE</span>,
                   monitor <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>

<span class="co"># --------------- step 3 - train for fairness  --------------------</span>

<span class="va">monitor</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/fair_train.html">fair_train</a></span><span class="op">(</span> n_ep_pan <span class="op">=</span> <span class="fl">17</span>,
                       dsl <span class="op">=</span> <span class="va">dsl</span>,
                       clf_model <span class="op">=</span> <span class="va">models</span><span class="op">$</span><span class="va">clf_model</span>,
                       adv_model <span class="op">=</span> <span class="va">models</span><span class="op">$</span><span class="va">adv_model</span>, 
                       clf_optimizer <span class="op">=</span> <span class="va">models</span><span class="op">$</span><span class="va">clf_optimizer</span>,
                       adv_optimizer <span class="op">=</span> <span class="va">models</span><span class="op">$</span><span class="va">adv_optimizer</span>,
                       dev <span class="op">=</span> <span class="va">dev</span>,
                       sensitive_train <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">sensitive_train</span>,
                       sensitive_test <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">sensitive_test</span>,  
                       batch_size <span class="op">=</span> <span class="fl">5</span>,   
                       learning_rate_adv <span class="op">=</span> <span class="fl">0.001</span>,  
                       learning_rate_clf <span class="op">=</span> <span class="fl">0.001</span>, 
                       lambda <span class="op">=</span> <span class="fl">130</span>,
                       verbose <span class="op">=</span> <span class="cn">TRUE</span>,
                       monitor <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>

<span class="co"># --------- step 4 - prepare outcomes and plot them  --------------</span>

<span class="fu"><a href="reference/plot_monitor.html">plot_monitor</a></span><span class="op">(</span>STP <span class="op">=</span> <span class="va">monitor</span><span class="op">$</span><span class="va">STP</span>,
             adversary_acc <span class="op">=</span> <span class="va">monitor</span><span class="op">$</span><span class="va">adversary_acc</span>,
             adversary_losses <span class="op">=</span> <span class="va">monitor</span><span class="op">$</span><span class="va">adversary_losses</span>,
             classifier_acc <span class="op">=</span> <span class="va">monitor</span><span class="op">$</span><span class="va">classifier_acc</span><span class="op">)</span>

<span class="va">exp_clf</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/explain_pan.html">explain_pan</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">test_y</span>,
                       model <span class="op">=</span> <span class="va">models</span><span class="op">$</span><span class="va">clf_model</span>,
                       label <span class="op">=</span> <span class="st">"PAN"</span>,
                       data <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">data_test</span>,
                       data_scaled <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">data_scaled_test</span>,
                       batch_size <span class="op">=</span> <span class="fl">5</span>,
                       dev <span class="op">=</span> <span class="va">dev</span>,
                       verbose <span class="op">=</span> <span class="cn">TRUE</span>
<span class="op">)</span>

<span class="va">fobject</span> <span class="op">&lt;-</span> <span class="fu">fairmodels</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/fairmodels/man/fairness_check.html">fairness_check</a></span><span class="op">(</span><span class="va">exp_PAN</span>,
                            protected <span class="op">=</span> <span class="va">data</span><span class="op">$</span><span class="va">protected_test</span>,
                            privileged <span class="op">=</span> <span class="st">"Male"</span>,
                            verbose <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">fobject</span><span class="op">)</span></code></pre></div>
</div>
<div id="fair-training-is-flexible" class="section level2">
<h2 class="hasAnchor">
<a href="#fair-training-is-flexible" class="anchor"></a>Fair training is flexible</h2>
<p><code>pretrain</code> function has optional parameters:</p>
<ul>
<li><p><code>clf_model</code> nn_module describing classifiers neural network architecture</p></li>
<li><p><code>adv_model</code> nn_module describing adversaries neural network architecture</p></li>
<li><p><code>clf_optimizer</code> torch object providing classifier optimizer from pretrain</p></li>
<li><p><code>trained</code> settles whether clf_model is trained or not</p></li>
</ul>
<p>which enables users to provide their own and even pretrained neural network models.</p>
<p>On the other hand, you can use FairPAN package from the very beginning starting from data preprocessing with <code><a href="reference/preprocess.html">preprocess()</a></code> function which provides every dataset that you will need for provided features.</p>
</div>
<div id="proper-evaluation" class="section level2">
<h2 class="hasAnchor">
<a href="#proper-evaluation" class="anchor"></a>Proper evaluation</h2>
<p>Although there are many metrics that measure fairness, our method focuses on optimizing <em>Statistical Parity ratio</em> ( (TP+FP)/(TP+FP+TN+FN) ) which describes the similarity between distributions of privileged and discriminated variables.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <div class="links">
<h2>Links</h2>
<ul class="list-unstyled">
<li>Browse source code at <br><a href="https://github.com/ModelOriented/FairPAN">https://​github.com/​ModelOriented/​FairPAN</a>
</li>
</ul>
</div>
<div class="license">
<h2>License</h2>
<ul class="list-unstyled">
<li><a href="https://www.r-project.org/Licenses/GPL-3">GPL-3</a></li>
</ul>
</div>
<div class="developers">
<h2>Developers</h2>
<ul class="list-unstyled">
<li>Hubert Ruczyński <br><small class="roles"> Author, maintainer </small>  </li>
<li>Jakub Wiśniewski <br><small class="roles"> Author, reviewer </small>  </li>
<li><a href="authors.html">All authors...</a></li>
</ul>
</div>

  <div class="dev-status">
<h2>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/ModelOriented/FairPAN/actions"><img src="https://github.com/ModelOriented/FairPAN/workflows/R-CMD-check/badge.svg" alt="R-CMD-check"></a></li>
<li><a href="https://codecov.io/gh/ModelOriented/FairPAN?branch=master"><img src="https://codecov.io/gh/ModelOriented/FairPAN/branch/master/graph/badge.svg" alt="Codecov test coverage"></a></li>
</ul>
</div>
</div>
</div>


      <footer><div class="copyright">
  <p>Developed by Hubert Ruczyński, Jakub Wiśniewski.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
